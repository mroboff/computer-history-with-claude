//! Single GPU Passthrough Script Generation
//!
//! Generates scripts for single GPU passthrough scenarios where the user's primary
//! GPU is passed to a VM, requiring the display manager to be stopped.

use anyhow::{Context, Result};
use std::fs;
use std::os::unix::fs::PermissionsExt;
use std::path::{Path, PathBuf};

use crate::hardware::{LookingGlassConfig, SingleGpuConfig};
use crate::vm::DiscoveredVm;

/// Generated scripts for single GPU passthrough
#[derive(Debug)]
pub struct GeneratedScripts {
    /// Path to the start script
    pub start_script: PathBuf,
    /// Path to the restore script
    pub restore_script: PathBuf,
    /// Path to the setup script
    pub setup_script: PathBuf,
}

/// Generate all single GPU passthrough scripts for a VM
pub fn generate_single_gpu_scripts(
    vm: &DiscoveredVm,
    config: &SingleGpuConfig,
) -> Result<GeneratedScripts> {
    let vm_dir = &vm.path;

    // Generate the start script
    let start_content = generate_start_script(vm, config)?;
    let start_path = vm_dir.join("single-gpu-start.sh");
    write_executable_script(&start_path, &start_content)?;

    // Generate the restore script
    let restore_content = generate_restore_script(config);
    let restore_path = vm_dir.join("single-gpu-restore.sh");
    write_executable_script(&restore_path, &restore_content)?;

    // Generate the setup script
    let setup_content = generate_setup_script(config);
    let setup_path = vm_dir.join("single-gpu-setup.sh");
    write_executable_script(&setup_path, &setup_content)?;

    Ok(GeneratedScripts {
        start_script: start_path,
        restore_script: restore_path,
        setup_script: setup_path,
    })
}

/// Write a script file and make it executable
fn write_executable_script(path: &Path, content: &str) -> Result<()> {
    fs::write(path, content)
        .with_context(|| format!("Failed to write script: {:?}", path))?;

    let mut perms = fs::metadata(path)?.permissions();
    perms.set_mode(0o755);
    fs::set_permissions(path, perms)?;

    Ok(())
}

/// Generate the main start script
fn generate_start_script(vm: &DiscoveredVm, config: &SingleGpuConfig) -> Result<String> {
    let gpu_addr = &config.gpu.address;
    let audio_addr = config.audio.as_ref().map(|a| a.address.as_str()).unwrap_or("");
    let original_driver = config.original_driver.module_name();
    let display_manager = config.display_manager.service_name();
    let vm_dir = vm.path.display();
    let vm_name = vm.display_name();

    // Get dependent modules to unload
    let modules_to_unload = config.original_driver.dependent_modules();
    let unload_modules_cmd = if !modules_to_unload.is_empty() {
        modules_to_unload
            .iter()
            .map(|m| format!("    modprobe -r {} 2>/dev/null || true", m))
            .collect::<Vec<_>>()
            .join("\n")
    } else {
        "    # No additional modules to unload".to_string()
    };

    // Looking Glass configuration
    let looking_glass_enabled = config.looking_glass.enabled;
    let ivshmem_size = config.looking_glass.ivshmem_size_mb;
    let lg_auto_launch = config.looking_glass.auto_launch_client;
    let lg_client = config
        .looking_glass
        .client_path
        .as_ref()
        .map(|p| p.display().to_string())
        .or_else(|| LookingGlassConfig::find_client().map(|p| p.display().to_string()))
        .unwrap_or_else(|| "looking-glass-client".to_string());

    // Build QEMU command from existing launch.sh
    let qemu_command = extract_qemu_command_for_passthrough(vm, config)?;

    let script = format!(
        r#"#!/bin/bash
# Single GPU Passthrough Start Script
# Generated by vm-curator for: {vm_name}
#
# This script must be run from a TTY (Ctrl+Alt+F3), not from a graphical terminal.
# It will stop your display manager, pass your GPU to the VM, and restore
# the display when the VM exits.

set -e

# ============================================================================
# Configuration (do not edit unless you know what you're doing)
# ============================================================================
VM_DIR="{vm_dir}"
VM_NAME="{vm_name}"
GPU_ADDR="{gpu_addr}"
AUDIO_ADDR="{audio_addr}"
ORIGINAL_DRIVER="{original_driver}"
DISPLAY_MANAGER="{display_manager}"
LOOKING_GLASS_ENABLED="{looking_glass_enabled}"
IVSHMEM_SIZE="{ivshmem_size}M"
LG_AUTO_LAUNCH="{lg_auto_launch}"
LG_CLIENT="{lg_client}"

# ============================================================================
# Safety Checks
# ============================================================================

# Must run as root or with sudo
if [[ $EUID -ne 0 ]]; then
    echo "This script must be run as root (use sudo)"
    exit 1
fi

# Must run from TTY, not graphical terminal
if [[ -n "$DISPLAY" ]] || [[ -n "$WAYLAND_DISPLAY" ]]; then
    echo "ERROR: This script must be run from a TTY (Ctrl+Alt+F3), not a graphical terminal"
    echo ""
    echo "Instructions:"
    echo "  1. Press Ctrl+Alt+F3 to switch to TTY3"
    echo "  2. Log in with your username"
    echo "  3. Run: sudo $0"
    exit 1
fi

# Check that VFIO modules are available
if ! modinfo vfio_pci &>/dev/null; then
    echo "ERROR: vfio_pci module not available"
    echo "Run the setup script first: $VM_DIR/single-gpu-setup.sh"
    exit 1
fi

# ============================================================================
# Cleanup Function
# ============================================================================

cleanup() {{
    local exit_code=$?
    echo ""
    echo "Cleaning up and restoring display..."

    # Unbind from vfio-pci
    if [[ -e "/sys/bus/pci/drivers/vfio-pci/$GPU_ADDR" ]]; then
        echo "$GPU_ADDR" > /sys/bus/pci/drivers/vfio-pci/unbind 2>/dev/null || true
    fi
    if [[ -n "$AUDIO_ADDR" ]] && [[ -e "/sys/bus/pci/drivers/vfio-pci/$AUDIO_ADDR" ]]; then
        echo "$AUDIO_ADDR" > /sys/bus/pci/drivers/vfio-pci/unbind 2>/dev/null || true
    fi

    # Clear driver_override
    echo "" > /sys/bus/pci/devices/$GPU_ADDR/driver_override 2>/dev/null || true
    if [[ -n "$AUDIO_ADDR" ]]; then
        echo "" > /sys/bus/pci/devices/$AUDIO_ADDR/driver_override 2>/dev/null || true
    fi

    # Rescan PCI bus
    echo 1 > /sys/bus/pci/rescan 2>/dev/null || true
    sleep 1

    # Rebind to original driver
    if [[ -n "$ORIGINAL_DRIVER" ]] && [[ "$ORIGINAL_DRIVER" != "vfio-pci" ]]; then
        modprobe "$ORIGINAL_DRIVER" 2>/dev/null || true
        sleep 1
        if [[ -e "/sys/bus/pci/devices/$GPU_ADDR" ]] && [[ ! -e "/sys/bus/pci/devices/$GPU_ADDR/driver" ]]; then
            echo "$GPU_ADDR" > /sys/bus/pci/drivers/$ORIGINAL_DRIVER/bind 2>/dev/null || true
        fi
    fi

    # Restart display manager
    echo "Starting display manager..."
    systemctl start "$DISPLAY_MANAGER" 2>/dev/null || true

    echo "Display restored."
    exit $exit_code
}}

trap cleanup EXIT INT TERM

# ============================================================================
# Stop Display Manager
# ============================================================================

echo "Stopping display manager ($DISPLAY_MANAGER)..."
systemctl stop "$DISPLAY_MANAGER"
sleep 2

# For NVIDIA, stop persistence daemon
if [[ "$ORIGINAL_DRIVER" == "nvidia" ]]; then
    systemctl stop nvidia-persistenced 2>/dev/null || true
    sleep 1
fi

# ============================================================================
# Unload GPU Driver
# ============================================================================

echo "Unloading GPU driver modules..."

# Kill any processes using the GPU (try common ones)
for proc in Xorg Xwayland gnome-shell kwin_wayland plasmashell; do
    pkill -9 "$proc" 2>/dev/null || true
done
sleep 2

# Unload driver modules
{unload_modules_cmd}

# Verify driver is unloaded
if [[ -e "/sys/bus/pci/devices/$GPU_ADDR/driver" ]]; then
    current_driver=$(basename $(readlink /sys/bus/pci/devices/$GPU_ADDR/driver))
    if [[ "$current_driver" != "vfio-pci" ]]; then
        echo "$GPU_ADDR" > /sys/bus/pci/drivers/$current_driver/unbind 2>/dev/null || true
    fi
fi

if [[ -n "$AUDIO_ADDR" ]] && [[ -e "/sys/bus/pci/devices/$AUDIO_ADDR/driver" ]]; then
    current_driver=$(basename $(readlink /sys/bus/pci/devices/$AUDIO_ADDR/driver))
    if [[ "$current_driver" != "vfio-pci" ]]; then
        echo "$AUDIO_ADDR" > /sys/bus/pci/drivers/$current_driver/unbind 2>/dev/null || true
    fi
fi

# ============================================================================
# Bind to VFIO
# ============================================================================

echo "Binding GPU to vfio-pci..."

modprobe vfio_pci

# Set driver override and bind
echo "vfio-pci" > /sys/bus/pci/devices/$GPU_ADDR/driver_override
echo "$GPU_ADDR" > /sys/bus/pci/drivers/vfio-pci/bind

if [[ -n "$AUDIO_ADDR" ]]; then
    echo "vfio-pci" > /sys/bus/pci/devices/$AUDIO_ADDR/driver_override
    echo "$AUDIO_ADDR" > /sys/bus/pci/drivers/vfio-pci/bind
fi

# Verify binding
if [[ ! -e "/sys/bus/pci/drivers/vfio-pci/$GPU_ADDR" ]]; then
    echo "ERROR: Failed to bind GPU to vfio-pci"
    exit 1
fi

echo "GPU successfully bound to vfio-pci"

# ============================================================================
# Looking Glass Setup (if enabled)
# ============================================================================

if [[ "$LOOKING_GLASS_ENABLED" == "true" ]]; then
    echo "Setting up Looking Glass IVSHMEM..."

    # Create shared memory file
    touch /dev/shm/looking-glass
    chown $(logname):kvm /dev/shm/looking-glass 2>/dev/null || chown root:root /dev/shm/looking-glass
    chmod 0660 /dev/shm/looking-glass
fi

# ============================================================================
# Start VM
# ============================================================================

echo ""
echo "============================================"
echo "Starting VM: $VM_NAME"
echo "============================================"
echo ""

# Start Looking Glass client in background (if enabled)
if [[ "$LOOKING_GLASS_ENABLED" == "true" ]] && [[ "$LG_AUTO_LAUNCH" == "true" ]]; then
    # Start on TTY7 after a delay
    (
        sleep 10
        sudo -u $(logname) DISPLAY=:0 "$LG_CLIENT" -F &
    ) &
    LG_PID=$!
fi

# Run QEMU
cd "$VM_DIR"
{qemu_command}

# Kill Looking Glass client if running
if [[ -n "${{LG_PID:-}}" ]]; then
    kill $LG_PID 2>/dev/null || true
fi

echo ""
echo "VM has exited."
# Cleanup will run via trap
"#
    );

    Ok(script)
}

/// Generate the emergency restore script
fn generate_restore_script(config: &SingleGpuConfig) -> String {
    let gpu_addr = &config.gpu.address;
    let audio_addr = config
        .audio
        .as_ref()
        .map(|a| a.address.as_str())
        .unwrap_or("");
    let original_driver = config.original_driver.module_name();
    let display_manager = config.display_manager.service_name();

    format!(
        r#"#!/bin/bash
# Single GPU Passthrough Restore Script
# Generated by vm-curator
#
# Use this script to restore your display if something goes wrong.
# Can be run from SSH or a recovery boot.

set -e

GPU_ADDR="{gpu_addr}"
AUDIO_ADDR="{audio_addr}"
ORIGINAL_DRIVER="{original_driver}"
DISPLAY_MANAGER="{display_manager}"

# Must run as root
if [[ $EUID -ne 0 ]]; then
    echo "This script must be run as root (use sudo)"
    exit 1
fi

echo "Restoring display..."

# Unbind from vfio-pci
if [[ -e "/sys/bus/pci/drivers/vfio-pci/$GPU_ADDR" ]]; then
    echo "Unbinding GPU from vfio-pci..."
    echo "$GPU_ADDR" > /sys/bus/pci/drivers/vfio-pci/unbind 2>/dev/null || true
fi

if [[ -n "$AUDIO_ADDR" ]] && [[ -e "/sys/bus/pci/drivers/vfio-pci/$AUDIO_ADDR" ]]; then
    echo "Unbinding audio from vfio-pci..."
    echo "$AUDIO_ADDR" > /sys/bus/pci/drivers/vfio-pci/unbind 2>/dev/null || true
fi

# Clear driver_override
echo "" > /sys/bus/pci/devices/$GPU_ADDR/driver_override 2>/dev/null || true
if [[ -n "$AUDIO_ADDR" ]]; then
    echo "" > /sys/bus/pci/devices/$AUDIO_ADDR/driver_override 2>/dev/null || true
fi

# Rescan PCI bus
echo "Rescanning PCI bus..."
echo 1 > /sys/bus/pci/rescan

sleep 2

# Load and bind to original driver
if [[ -n "$ORIGINAL_DRIVER" ]] && [[ "$ORIGINAL_DRIVER" != "vfio-pci" ]]; then
    echo "Loading $ORIGINAL_DRIVER driver..."
    modprobe "$ORIGINAL_DRIVER" 2>/dev/null || true
    sleep 2

    # Try to bind
    if [[ -e "/sys/bus/pci/devices/$GPU_ADDR" ]] && [[ ! -e "/sys/bus/pci/devices/$GPU_ADDR/driver" ]]; then
        echo "$GPU_ADDR" > /sys/bus/pci/drivers/$ORIGINAL_DRIVER/bind 2>/dev/null || true
    fi
fi

# Restart display manager
echo "Starting display manager..."
systemctl start "$DISPLAY_MANAGER" 2>/dev/null || true

echo ""
echo "Restore complete!"
echo "If display still doesn't work, try rebooting."
"#
    )
}

/// Generate the one-time setup script
fn generate_setup_script(config: &SingleGpuConfig) -> String {
    let looking_glass_enabled = config.looking_glass.enabled;
    let ivshmem_size = config.looking_glass.ivshmem_size_mb;
    let original_driver = config.original_driver.module_name();

    // Build modprobe softdep line
    let softdep_line = format!(
        "softdep {} pre: vfio-pci",
        original_driver
    );

    format!(
        r#"#!/bin/bash
# Single GPU Passthrough Setup Script
# Generated by vm-curator
#
# Run this script once to set up your system for single GPU passthrough.
# This script:
#   - Adds VFIO modules to initramfs
#   - Creates modprobe configuration
#   - Sets up Looking Glass permissions (if enabled)

set -e

LOOKING_GLASS_ENABLED="{looking_glass_enabled}"
IVSHMEM_SIZE="{ivshmem_size}"

# Must run as root
if [[ $EUID -ne 0 ]]; then
    echo "This script must be run as root (use sudo)"
    exit 1
fi

echo "Setting up single GPU passthrough..."
echo ""

# ============================================================================
# VFIO Modules
# ============================================================================

echo "[1/4] Configuring VFIO modules..."

# Add vfio modules to /etc/modules-load.d/
cat > /etc/modules-load.d/vfio.conf << 'EOF'
# VFIO modules for GPU passthrough
vfio
vfio_iommu_type1
vfio_pci
EOF

# Create modprobe configuration for driver loading order
cat > /etc/modprobe.d/vfio.conf << 'EOF'
# Load VFIO before GPU driver
{softdep_line}
options vfio_pci disable_vga=1
EOF

echo "  Created /etc/modules-load.d/vfio.conf"
echo "  Created /etc/modprobe.d/vfio.conf"

# ============================================================================
# Initramfs
# ============================================================================

echo ""
echo "[2/4] Updating initramfs..."

# Detect distro and update initramfs accordingly
if command -v mkinitcpio &>/dev/null; then
    # Arch Linux
    echo "  Detected Arch Linux, running mkinitcpio..."

    # Check if MODULES array needs updating
    if ! grep -q "vfio_pci" /etc/mkinitcpio.conf; then
        echo "  NOTE: You may need to add 'vfio_pci vfio vfio_iommu_type1' to MODULES in /etc/mkinitcpio.conf"
    fi

    mkinitcpio -P
elif command -v update-initramfs &>/dev/null; then
    # Debian/Ubuntu
    echo "  Detected Debian/Ubuntu, running update-initramfs..."
    update-initramfs -u -k all
elif command -v dracut &>/dev/null; then
    # Fedora/RHEL
    echo "  Detected Fedora/RHEL, running dracut..."
    dracut -f --regenerate-all
else
    echo "  WARNING: Could not detect initramfs tool"
    echo "  Please manually regenerate your initramfs"
fi

# ============================================================================
# Looking Glass Setup
# ============================================================================

if [[ "$LOOKING_GLASS_ENABLED" == "true" ]]; then
    echo ""
    echo "[3/4] Setting up Looking Glass..."

    # Create tmpfiles.d configuration for IVSHMEM
    cat > /etc/tmpfiles.d/10-looking-glass.conf << EOF
# Looking Glass IVSHMEM device
f /dev/shm/looking-glass 0660 root kvm -
EOF

    echo "  Created /etc/tmpfiles.d/10-looking-glass.conf"

    # Create the file now
    touch /dev/shm/looking-glass
    chmod 0660 /dev/shm/looking-glass

    # Try to set ownership
    if getent group kvm &>/dev/null; then
        chown root:kvm /dev/shm/looking-glass
        echo "  Created /dev/shm/looking-glass (owned by root:kvm)"
    else
        echo "  Created /dev/shm/looking-glass"
        echo "  NOTE: 'kvm' group not found. You may need to adjust permissions."
    fi

    # Add user to kvm group
    REAL_USER="${{SUDO_USER:-$USER}}"
    if [[ "$REAL_USER" != "root" ]] && getent group kvm &>/dev/null; then
        if ! groups "$REAL_USER" | grep -q kvm; then
            usermod -aG kvm "$REAL_USER"
            echo "  Added $REAL_USER to 'kvm' group"
            echo "  NOTE: Log out and back in for group change to take effect"
        fi
    fi
else
    echo ""
    echo "[3/4] Skipping Looking Glass setup (not enabled)"
fi

# ============================================================================
# Summary
# ============================================================================

echo ""
echo "[4/4] Setup complete!"
echo ""
echo "============================================"
echo "Next steps:"
echo "============================================"
echo ""
echo "1. Reboot your system for changes to take effect"
echo ""
echo "2. After reboot, to use single GPU passthrough:"
echo "   a. Press Ctrl+Alt+F3 to switch to TTY3"
echo "   b. Log in with your username"
echo "   c. Run: sudo ./single-gpu-start.sh"
echo ""
echo "3. If anything goes wrong:"
echo "   - SSH into your machine and run: sudo ./single-gpu-restore.sh"
echo "   - Or reboot the system"
echo ""

if [[ "$LOOKING_GLASS_ENABLED" == "true" ]]; then
    echo "Looking Glass notes:"
    echo "  - Install Looking Glass Host application in your Windows VM"
    echo "  - Connect a dummy HDMI/DP plug to your GPU"
    echo "  - The Looking Glass client will auto-start when the VM launches"
    echo ""
fi

echo "============================================"
"#
    )
}

/// Extract and modify QEMU command from the VM's launch script for GPU passthrough
fn extract_qemu_command_for_passthrough(vm: &DiscoveredVm, config: &SingleGpuConfig) -> Result<String> {
    let launch_script = fs::read_to_string(&vm.launch_script)
        .with_context(|| format!("Failed to read launch script: {:?}", vm.launch_script))?;

    // Find the QEMU command in the script
    let mut qemu_lines = Vec::new();
    let mut in_qemu_command = false;
    let mut found_qemu = false;

    for line in launch_script.lines() {
        let trimmed = line.trim();

        // Check if this is the start of a QEMU command
        if !in_qemu_command {
            if (trimmed.starts_with("qemu-system-")
                || trimmed.starts_with("exec qemu-system-")
                || trimmed.starts_with("\"$QEMU\"")
                || trimmed.starts_with("$QEMU "))
                && !trimmed.starts_with('#')
            {
                in_qemu_command = true;
                found_qemu = true;
            }
        }

        if in_qemu_command {
            qemu_lines.push(line.to_string());

            // Check if this is the last line of the command
            if !trimmed.ends_with('\\') {
                break;
            }
        }
    }

    if !found_qemu {
        // Fallback: generate a basic QEMU command
        return Ok(generate_basic_qemu_command(vm, config));
    }

    // Build the modified QEMU command
    let mut qemu_cmd = qemu_lines.join("\n");

    // Remove existing -display if present (we'll use the GPU's display)
    let display_re = regex::Regex::new(r"-display\s+\S+").unwrap();
    qemu_cmd = display_re.replace_all(&qemu_cmd, "").to_string();

    // Remove existing -vga if present
    let vga_re = regex::Regex::new(r"-vga\s+\S+").unwrap();
    qemu_cmd = vga_re.replace_all(&qemu_cmd, "").to_string();

    // Build passthrough arguments
    let mut passthrough_args = Vec::new();

    // GPU passthrough
    passthrough_args.push(format!(
        "-device vfio-pci,host={},multifunction=on,x-vga=on",
        config.gpu.address
    ));

    // Audio passthrough (if present)
    if let Some(ref audio) = config.audio {
        passthrough_args.push(format!(
            "-device vfio-pci,host={}",
            audio.address
        ));
    }

    // Looking Glass IVSHMEM (if enabled)
    if config.looking_glass.enabled {
        passthrough_args.push(
            "-device ivshmem-plain,memdev=ivshmem,bus=pcie.0".to_string()
        );
        passthrough_args.push(format!(
            "-object memory-backend-file,id=ivshmem,share=on,mem-path=/dev/shm/looking-glass,size={}",
            config.looking_glass.ivshmem_size_str()
        ));
    }

    // Display settings for passthrough (no display, or use Looking Glass)
    if config.looking_glass.enabled {
        passthrough_args.push("-display none".to_string());
        passthrough_args.push("-vga none".to_string());
    } else {
        // Use the physical GPU output
        passthrough_args.push("-display none".to_string());
        passthrough_args.push("-vga none".to_string());
    }

    // Add passthrough args to the QEMU command
    let passthrough_str = passthrough_args.join(" \\\n    ");

    // Find the end of the QEMU command and insert our args
    if let Some(last_backslash) = qemu_cmd.rfind('\\') {
        let (before, _) = qemu_cmd.split_at(last_backslash);
        qemu_cmd = format!(
            "{} \\\n    {}",
            before.trim_end(),
            passthrough_str
        );
    } else {
        // No continuation, just append
        qemu_cmd = format!("{} \\\n    {}", qemu_cmd.trim_end(), passthrough_str);
    }

    Ok(qemu_cmd)
}

/// Generate a basic QEMU command when the launch script can't be parsed
fn generate_basic_qemu_command(vm: &DiscoveredVm, config: &SingleGpuConfig) -> String {
    let qemu_emulator = vm.config.emulator.command();
    let memory = vm.config.memory_mb;
    let cpu_cores = vm.config.cpu_cores;

    let mut cmd = format!(
        r#"{} \
    -name "{}" \
    -machine q35,accel=kvm \
    -cpu host \
    -m {} \
    -smp {} \
    -enable-kvm"#,
        qemu_emulator,
        vm.display_name(),
        memory,
        cpu_cores
    );

    // Add disk
    if let Some(disk) = vm.config.disks.first() {
        let format_str = match &disk.format {
            crate::vm::qemu_config::DiskFormat::Qcow2 => "qcow2",
            crate::vm::qemu_config::DiskFormat::Raw => "raw",
            crate::vm::qemu_config::DiskFormat::Vmdk => "vmdk",
            crate::vm::qemu_config::DiskFormat::Vdi => "vdi",
            crate::vm::qemu_config::DiskFormat::Other(s) => s.as_str(),
        };
        cmd.push_str(&format!(
            r#" \
    -drive file={},format={},if=virtio"#,
            disk.path.display(),
            format_str
        ));
    }

    // Add GPU passthrough
    cmd.push_str(&format!(
        r#" \
    -device vfio-pci,host={},multifunction=on,x-vga=on"#,
        config.gpu.address
    ));

    // Add audio (if present)
    if let Some(ref audio) = config.audio {
        cmd.push_str(&format!(
            r#" \
    -device vfio-pci,host={}"#,
            audio.address
        ));
    }

    // Looking Glass IVSHMEM
    if config.looking_glass.enabled {
        cmd.push_str(&format!(
            r#" \
    -device ivshmem-plain,memdev=ivshmem,bus=pcie.0 \
    -object memory-backend-file,id=ivshmem,share=on,mem-path=/dev/shm/looking-glass,size={}"#,
            config.looking_glass.ivshmem_size_str()
        ));
    }

    // Display settings
    cmd.push_str(
        r#" \
    -display none \
    -vga none"#,
    );

    // USB for keyboard/mouse
    cmd.push_str(
        r#" \
    -usb \
    -device usb-host,vendorid=0x0000,productid=0x0000"#,
    );

    cmd
}

/// Delete single GPU scripts for a VM
pub fn delete_scripts(vm_path: &Path) -> Result<()> {
    let scripts = [
        "single-gpu-start.sh",
        "single-gpu-restore.sh",
        "single-gpu-setup.sh",
    ];

    for script in scripts {
        let path = vm_path.join(script);
        if path.exists() {
            fs::remove_file(&path)
                .with_context(|| format!("Failed to delete script: {:?}", path))?;
        }
    }

    Ok(())
}
